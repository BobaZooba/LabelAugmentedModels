# @package _group_
class_path: label_augmented.models.Transformer
parameters:
  model_dim: $(general.model_dim)
  embedding_dim: 384
  vocab_size: $(general.vocab_size)
  num_heads: 12
  feed_forward_dim: 1536
  num_layers: $(general.num_layers)
  n_positions: $(general.max_length)
  n_segments: 0
  dropout: 0.1
  norm_type: rms
  zeroing_pad: False
  head_dim: null
  activation: geglu
  use_attention_bias: False
  shared_relative_positions: True
  use_relative_positions: True
  max_relative_position: 10
  use_bias_positions: True
  use_fusion_gate: False
  pad_index: $(general.pad_index)